# Observability Pattern for Brand Research Pipeline
## Persistent Checkpoint Logging Standard

### Executive Summary

This document defines the standard observability pattern for all research phases in our brand intelligence pipeline. Every research phase MUST implement persistent checkpoint logging for recovery, debugging, and performance analysis.

---

## üéØ **Core Observability Requirements**

### **Four-File Observability Architecture**

Every research phase must generate exactly 4 files for complete observability:

```
research_phases/
‚îú‚îÄ‚îÄ {phase}_research.md                    # üìÑ Research content (markdown)
‚îú‚îÄ‚îÄ {phase}_research_metadata.json         # üìä Quality & summary metrics  
‚îú‚îÄ‚îÄ {phase}_research_sources.json          # üîç Source provenance tracking
‚îî‚îÄ‚îÄ {phase}_research_progress.json         # üìà Step-by-step checkpoint log
```

### **Checkpoint Log Structure**

```json
{
  "research_session_id": "uuid",
  "brand_domain": "specialized.com",
  "phase": "foundation_research",
  "session_start": "2025-06-25T17:53:08.067215Z",
  "session_end": "2025-06-25T17:55:23.031234Z", 
  "total_checkpoints": 6,
  "final_status": "completed",
  "total_duration_seconds": 134.96,
  "quality_score": 0.8,
  "checkpoints": [
    {
      "checkpoint_id": "uuid",
      "timestamp": "2025-06-25T17:53:08.067215Z",
      "step_id": "uuid", 
      "step_type": "foundation_research",
      "status": "running",
      "progress_percentage": 16.7,
      "duration_seconds": 27.95,
      "current_operation": "üìä Step 1: Gathering comprehensive foundation data...",
      "quality_score": null,
      "error_message": null,
      "warnings": []
    }
  ]
}
```

---

## üìã **Implementation Pattern for All Research Phases**

### **1. Constructor Pattern**

```python
class {Phase}Researcher:
    def __init__(self, storage_manager=None):
        """Initialize researcher with checkpoint logging"""
        self.storage_manager = storage_manager or get_account_storage_provider()
        
        # Create progress tracker with checkpoint logging enabled
        self.progress_tracker = ProgressTracker(
            storage_manager=self.storage_manager,
            enable_checkpoints=True  # ‚úÖ REQUIRED
        )
        
        # Add console listener for real-time updates
        console_listener = create_console_listener()
        self.progress_tracker.add_progress_listener(console_listener)
```

### **2. Research Method Pattern**

```python
async def research_{phase}(self, brand_domain: str, force_refresh: bool = False) -> Dict[str, Any]:
    """Research {phase} phase with checkpoint logging"""
    start_time = time.time()
    
    # Create progress step with appropriate operations count
    step_id = self.progress_tracker.create_step(
        step_type=StepType.{PHASE}_RESEARCH,
        brand=brand_domain,
        phase_name="{Phase} Research",
        total_operations=6  # Adjust based on phase complexity
    )
    
    try:
        self.progress_tracker.start_step(step_id, "Checking cache and initializing...")
        
        # Cache check
        if not force_refresh:
            cached_result = await self._load_cached_{phase}(brand_domain)
            if cached_result:
                self.progress_tracker.complete_step(
                    step_id, 
                    output_files=cached_result.get("files", []),
                    quality_score=cached_result.get("quality_score"),
                    cache_hit=True  # ‚úÖ Track cache hits
                )
                return cached_result
        
        # Step 1: Data gathering
        self.progress_tracker.update_progress(step_id, 1, "üìä Step 1: {Operation description}")
        data = await self._gather_{phase}_data(brand_domain)
        
        # Step 2: Analysis  
        self.progress_tracker.update_progress(step_id, 2, "üß† Step 2: {Analysis description}")
        analysis = await self._analyze_{phase}_data(brand_domain, data)
        
        # Step 3: Synthesis
        self.progress_tracker.update_progress(step_id, 3, "üéØ Step 3: {Synthesis description}")
        results = await self._synthesize_{phase}_intelligence(brand_domain, analysis)
        
        # Save results
        saved_files = await self._save_{phase}_research(brand_domain, results)
        
        # Complete with quality score
        self.progress_tracker.complete_step(
            step_id,
            output_files=saved_files,
            quality_score=results.get("confidence_score", 0.8),
            cache_hit=False  # ‚úÖ Track fresh research
        )
        
        return results
        
    except Exception as e:
        # ‚úÖ CRITICAL: Always log failures
        self.progress_tracker.fail_step(step_id, str(e))
        logger.error(f"‚ùå Error in {phase} research for {brand_domain}: {e}")
        raise
```

### **3. Error Handling Pattern**

```python
# Abort conditions that trigger failure checkpoints
if critical_failure_condition:
    error_msg = f"ABORTING: {specific_reason}"
    logger.error(f"üö® {error_msg}")
    # Progress tracker will automatically log failure checkpoint
    raise RuntimeError(error_msg)

# Warnings that create warning checkpoints  
if quality_concern:
    warning_msg = f"‚ö†Ô∏è {quality_issue_description}"
    logger.warning(warning_msg)
    self.progress_tracker.add_warning(step_id, warning_msg)
```

---

## üìä **Research Phase Specifications**

### **Phase 1: Foundation Research** ‚úÖ **IMPLEMENTED**
- **Duration**: 3-5 minutes
- **Operations**: 6 (cache check, data gathering, analysis, synthesis, storage, completion)
- **Checkpoint Triggers**: Step start, progress updates (every 16.7%), completion/failure
- **Quality Metrics**: Confidence score, source count, search success rate

### **Phase 2: Market Positioning Research** üîÑ **PENDING**
- **Duration**: 2-4 minutes  
- **Operations**: 5 (cache check, competitor analysis, positioning synthesis, validation, storage)
- **Checkpoint Triggers**: Step start, competitor discovery, analysis completion, storage
- **Quality Metrics**: Competitive coverage, positioning accuracy, market insights quality

### **Phase 3: Product Intelligence Research** üîÑ **PENDING**
- **Duration**: 2-3 minutes
- **Operations**: 4 (cache check, product discovery, feature analysis, storage)
- **Checkpoint Triggers**: Step start, product catalog crawl, feature extraction, storage
- **Quality Metrics**: Product coverage, feature completeness, catalog accuracy

### **Phase 4: Customer Intelligence Research** üîÑ **PENDING**
- **Duration**: 2-3 minutes
- **Operations**: 5 (cache check, demographic analysis, psychographic analysis, synthesis, storage)
- **Checkpoint Triggers**: Step start, data collection, analysis phases, storage
- **Quality Metrics**: Customer insights quality, data diversity, analysis depth

### **Phase 5: Voice & Messaging Analysis** üîÑ **PENDING**
- **Duration**: 1-2 minutes
- **Operations**: 4 (cache check, content analysis, voice synthesis, storage)
- **Checkpoint Triggers**: Step start, content extraction, voice analysis, storage
- **Quality Metrics**: Voice consistency, messaging clarity, tone accuracy

### **Phase 6: Interview Integration** üîÑ **PENDING**
- **Duration**: 3-5 minutes
- **Operations**: 6 (cache check, transcript processing, insight extraction, integration, validation, storage)
- **Checkpoint Triggers**: Step start, transcript analysis, insight extraction, integration, storage
- **Quality Metrics**: Interview coverage, insight quality, integration completeness

### **Phase 7: Integration & Synthesis** üîÑ **PENDING**
- **Duration**: 1-2 minutes
- **Operations**: 4 (cache check, cross-validation, final synthesis, storage)
- **Checkpoint Triggers**: Step start, validation checks, synthesis completion, storage
- **Quality Metrics**: Cross-validation success, synthesis coherence, final quality score

---

## üîç **Checkpoint Analysis & Recovery**

### **Progress Log Loading**

```python
# Load checkpoint history for debugging/analysis
progress_log = progress_tracker.load_progress_log("specialized.com", "foundation_research")

if progress_log:
    print(f"Session {progress_log['research_session_id']}")
    print(f"Duration: {progress_log['total_duration_seconds']:.1f}s")
    print(f"Final Status: {progress_log['final_status']}")
    print(f"Quality Score: {progress_log['quality_score']}")
    
    for checkpoint in progress_log['checkpoints']:
        print(f"  {checkpoint['timestamp']}: {checkpoint['current_operation']} ({checkpoint['progress_percentage']:.1f}%)")
```

### **Failure Recovery Pattern**

```python
# Check for previous failed sessions
progress_log = progress_tracker.load_progress_log(brand, phase)
if progress_log and progress_log['final_status'] == 'failed':
    logger.warning(f"‚ö†Ô∏è Previous {phase} research failed at {progress_log['session_end']}")
    
    # Analyze failure point
    failed_checkpoint = progress_log['checkpoints'][-1]
    logger.info(f"üîç Last operation: {failed_checkpoint['current_operation']}")
    logger.info(f"üîç Error: {failed_checkpoint.get('error_message', 'Unknown')}")
    
    # Implement recovery logic based on failure point
    if failed_checkpoint['progress_percentage'] < 50:
        logger.info("üîÑ Restarting from beginning...")
    else:
        logger.info("üîÑ Attempting to resume from safe checkpoint...")
```

---

## üìà **Performance Monitoring**

### **Success Metrics Tracking**

- **Research Completion Rate**: % of phases that complete successfully
- **Average Duration**: Time per phase across all brands  
- **Quality Score Distribution**: Distribution of confidence scores
- **Cache Hit Rate**: % of requests served from cache
- **Error Recovery Rate**: % of failed sessions that recover successfully

### **Performance Analysis Queries**

```python
# Analyze research performance across brands
def analyze_research_performance(storage_manager, phase: str):
    """Generate performance report for research phase"""
    
    reports = []
    for brand in get_all_brands():
        progress_log = progress_tracker.load_progress_log(brand, phase)
        if progress_log:
            reports.append({
                'brand': brand,
                'duration': progress_log['total_duration_seconds'],
                'status': progress_log['final_status'],
                'quality': progress_log['quality_score'],
                'checkpoints': progress_log['total_checkpoints']
            })
    
    # Generate summary statistics
    completed = [r for r in reports if r['status'] == 'completed']
    avg_duration = sum(r['duration'] for r in completed) / len(completed)
    avg_quality = sum(r['quality'] for r in completed if r['quality']) / len(completed)
    
    return {
        'total_sessions': len(reports),
        'completion_rate': len(completed) / len(reports),
        'avg_duration_seconds': avg_duration,
        'avg_quality_score': avg_quality
    }
```

---

## üöÄ **Implementation Checklist**

### **For Each New Research Phase:**

- [ ] **Constructor**: Initialize ProgressTracker with `enable_checkpoints=True`
- [ ] **Step Creation**: Create step with appropriate `StepType` and operation count
- [ ] **Progress Updates**: Call `update_progress()` at logical phase boundaries  
- [ ] **Error Handling**: Use `fail_step()` for failures, `add_warning()` for quality issues
- [ ] **Completion**: Call `complete_step()` with quality score and output files
- [ ] **File Structure**: Generate all 4 observability files (content, metadata, sources, progress)
- [ ] **Testing**: Verify checkpoint logs are created and contain expected data
- [ ] **Recovery**: Implement progress log loading for failure analysis

### **Quality Assurance:**

- [ ] **Checkpoint Coverage**: Verify checkpoints cover all major operations
- [ ] **Error Scenarios**: Test failure checkpoint creation and error logging
- [ ] **Performance Impact**: Ensure checkpoint logging doesn't significantly slow research
- [ ] **Storage Integration**: Verify checkpoint logs save to both GCP and local storage
- [ ] **Recovery Testing**: Test progress log loading and failure analysis

---

## üí° **Benefits of This Pattern**

### **For Development:**
- **Complete Audit Trail**: Every research session fully documented
- **Failure Analysis**: Detailed debugging information for failed operations
- **Performance Optimization**: Identify bottlenecks and optimization opportunities
- **Quality Tracking**: Monitor research quality trends over time

### **For Operations:**
- **Recovery Capability**: Resume from failures or interruptions
- **Monitoring Dashboards**: Real-time and historical research status
- **SLA Compliance**: Track research completion times and success rates
- **Quality Assurance**: Systematic quality monitoring across all phases

### **For Users:**
- **Transparency**: Complete visibility into research progress
- **Confidence**: Quality scores and source tracking for all research
- **Reliability**: Automatic recovery and error handling
- **Performance**: Optimized research pipeline based on performance data

---

**This observability pattern is now the REQUIRED standard for all research phases in our implementation plan.** 
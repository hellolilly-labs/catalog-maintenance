#!/usr/bin/env python3
"""
Test Enhanced Prompt Generation for Conversation Engine Integration

Tests the prompt generation pipeline that creates intelligent, context-aware
prompts stored in Langfuse for consumption by the Conversation Engine.
"""

import asyncio
import json
import logging
from datetime import datetime

from src.agents.communication_hub import AgentCommunicationHub
from src.agents.psychology_agent import create_psychology_agent
from src.agents.product_intelligence_agent import create_product_intelligence_agent
from src.agents.sales_strategy_agent import create_sales_strategy_agent
from src.agents.prompt_generator import create_prompt_generator

# Configure logging for testing
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

async def test_enhanced_prompt_generation():
    """Test the complete enhanced prompt generation pipeline"""
    
    print("üéØ Testing Enhanced Prompt Generation for Conversation Engine")
    print("=" * 70)
    
    # Initialize communication hub with multiple agents
    hub = AgentCommunicationHub()
    psychology_agent = create_psychology_agent()
    product_agent = create_product_intelligence_agent()
    sales_agent = create_sales_strategy_agent()
    
    hub.register_agent(psychology_agent)
    hub.register_agent(product_agent)
    hub.register_agent(sales_agent)
    
    # Sample brand intelligence (would come from our research phases)
    brand_intelligence = {
        "brand_name": "Specialized",
        "foundation": {
            "core_values": ["innovation", "performance", "authenticity", "rider-first engineering"]
        },
        "voice_messaging": {
            "tone": "technical expert with passionate enthusiasm",
            "personality": ["knowledgeable", "performance-focused", "authentic", "helpful"]
        },
        "customer_cultural": {
            "target_segments": ["serious cyclists", "commuters", "racing enthusiasts"]
        }
    }
    
    # Test scenarios that should generate different prompts
    test_scenarios = [
        {
            "scenario": "Excited Technical Customer",
            "message": "I'm really excited about getting a new road bike! I need detailed specs on your fastest models.",
            "conversation_id": "prompt_test_001",
            "expected_psychology": {
                "emotional_state": "excited",
                "communication_style": "technical",
                "decision_style": "analytical"
            }
        },
        {
            "scenario": "Price-Sensitive Confused Customer", 
            "message": "I'm confused by all these options and they seem expensive. Just need something simple.",
            "conversation_id": "prompt_test_002",
            "expected_psychology": {
                "emotional_state": "confused",
                "communication_style": "casual",
                "price_sensitivity": "high"
            }
        },
        {
            "scenario": "Ready-to-Buy Social Customer",
            "message": "My friends all have Specialized bikes and love them. I'm ready to order one today!",
            "conversation_id": "prompt_test_003",
            "expected_psychology": {
                "emotional_state": "excited",
                "decision_style": "social",
                "urgency_level": "high"
            }
        }
    ]
    
    # Process each scenario and generate enhanced prompts
    for scenario in test_scenarios:
        print(f"\nüé¨ Scenario: {scenario['scenario']}")
        print("-" * 50)
        print(f"üìù Customer Message: '{scenario['message']}'")
        
        # Generate enhanced prompt
        start_time = datetime.now()
        
        prompt_result = await hub.generate_enhanced_prompt(
            message=scenario["message"],
            conversation_id=scenario["conversation_id"],
            brand_domain="specialized.com",
            brand_intelligence=brand_intelligence,
            livekit_room_id=f"room_{scenario['conversation_id']}",
            audio_enabled=True,
            video_enabled=False
        )
        
        processing_time = (datetime.now() - start_time).total_seconds() * 1000
        
        # Display results
        print(f"\n‚è±Ô∏è  Total Processing Time: {processing_time:.1f}ms")
        print(f"üóùÔ∏è  Prompt Key: {prompt_result['prompt_key']}")
        print(f"üéØ Confidence Score: {prompt_result['confidence_score']:.2f}")
        print(f"ü§ñ Agents Used: {', '.join(prompt_result['agent_insights_used'])}")
        
        # Show psychology insights detected
        psychology_vars = prompt_result['prompt_variables'].get('customer_psychology', {})
        print(f"\nüß† Psychology Analysis:")
        print(f"   Emotional State: {psychology_vars.get('emotional_state', 'unknown')}")
        print(f"   Communication Style: {psychology_vars.get('communication_style', 'unknown')}")
        print(f"   Decision Style: {psychology_vars.get('decision_making_style', 'unknown')}")
        print(f"   Price Sensitivity: {psychology_vars.get('price_sensitivity', 'unknown')}")
        print(f"   Urgency Level: {psychology_vars.get('urgency_level', 'unknown')}")
        
        # Show product intelligence insights
        product_vars = prompt_result['prompt_variables'].get('product_intelligence', {})
        print(f"\nüõçÔ∏è Product Intelligence:")
        print(f"   Priority Products: {product_vars.get('priority_products', [])}")
        print(f"   Upsell Opportunities: {product_vars.get('upsell_opportunities', [])}")
        print(f"   Competitive Advantages: {product_vars.get('competitive_advantages', [])}")
        print(f"   Confidence Level: {product_vars.get('confidence_level', 'unknown')}")
        
        # Show sales strategy insights
        sales_vars = prompt_result['prompt_variables'].get('sales_strategy', {})
        print(f"\nüíº Sales Strategy:")
        print(f"   Sales Approach: {sales_vars.get('sales_approach', 'unknown')}")
        print(f"   Buying Signals: {sales_vars.get('buying_signals', [])}")
        print(f"   Objection Signals: {sales_vars.get('objection_signals', [])}")
        print(f"   Closing Opportunities: {sales_vars.get('closing_opportunities', [])}")
        print(f"   Confidence Level: {sales_vars.get('confidence_level', 'unknown')}")
        
        # Show real-time optimization
        optimization = prompt_result['prompt_variables'].get('real_time_optimization', {})
        print(f"\n‚ö° Real-Time Optimization:")
        print(f"   Response Length: {optimization.get('recommended_response_length', 'unknown')}")
        print(f"   Suggested Tone: {optimization.get('suggested_tone', 'unknown')}")
        print(f"   Priority Topics: {optimization.get('priority_topics', [])}")
        print(f"   Immediate Opportunities: {optimization.get('immediate_opportunities', [])}")
        
        # Show brand context
        brand_context = prompt_result['prompt_variables'].get('brand_context', {})
        print(f"\nüè¢ Brand Context:")
        print(f"   Brand Name: {brand_context.get('brand_name', 'unknown')}")
        print(f"   Brand Voice: {brand_context.get('brand_voice', 'unknown')}")
        print(f"   Core Values: {brand_context.get('core_values', [])}")
        
        # Show LiveKit context
        livekit_context = prompt_result['conversation_context']
        print(f"\nüéôÔ∏è  LiveKit Context:")
        print(f"   Room ID: {livekit_context.get('livekit_room_id', 'unknown')}")
        print(f"   Conversation Stage: {livekit_context.get('conversation_stage', 'unknown')}")
        print(f"   Customer Intent: {livekit_context.get('customer_intent', 'unknown')}")
        
        # Show a snippet of the enhanced prompt
        enhanced_prompt = prompt_result['enhanced_prompt']
        prompt_snippet = enhanced_prompt[:300] + "..." if len(enhanced_prompt) > 300 else enhanced_prompt
        print(f"\nüìã Enhanced Prompt Preview:")
        print(f"   {prompt_snippet}")
        
        # Validate expected psychology insights
        expected = scenario.get('expected_psychology', {})
        actual = psychology_vars
        
        print(f"\n‚úÖ Psychology Validation:")
        for key, expected_value in expected.items():
            actual_value = actual.get(key, 'unknown')
            match = "‚úÖ" if expected_value == actual_value else "‚ö†Ô∏è"
            print(f"   {match} {key}: expected '{expected_value}', got '{actual_value}'")

async def test_prompt_generator_standalone():
    """Test the prompt generator in isolation"""
    
    print("\n\nüéØ Testing Enhanced Prompt Generator Standalone")
    print("=" * 55)
    
    # Create a mock enhanced context
    from src.agents.context import ConversationContext, EnhancedContext, ConversationStage
    from src.agents.base_agent import AgentInsight
    
    # Create conversation context
    context = ConversationContext(
        conversation_id="standalone_test",
        brand_domain="specialized.com"
    )
    context.conversation_stage = ConversationStage.CONSIDERATION
    context.livekit_room_id = "room_standalone_test"
    context.audio_enabled = True
    
    # Create mock psychology insight
    psychology_insight = AgentInsight(
        agent_name="psychology_agent",
        confidence_score=0.85,
        timestamp=datetime.now(),
        insights={
            "emotional_state": "excited",
            "communication_style": "technical",
            "decision_making_style": "analytical",
            "price_sensitivity": "low",
            "urgency_level": "medium"
        },
        recommendations=[
            "Use detailed specifications and technical details",
            "Match customer's enthusiasm and energy level",
            "Focus on performance metrics and comparisons"
        ],
        metadata={"analysis_type": "psychology"},
        processing_time_ms=15.0
    )
    
    # Create enhanced context
    enhanced_context = EnhancedContext(
        conversation_context=context,
        psychology_insights=psychology_insight,
        total_processing_time_ms=25.0,
        insights_used=["psychology_agent"],
        confidence_score=0.85,
        recommended_response_length="detailed",
        suggested_tone="technical",
        priority_topics=["performance", "specifications"],
        immediate_opportunities=["technical_deep_dive"]
    )
    
    # Test prompt generation
    prompt_generator = create_prompt_generator()
    
    brand_intelligence = {
        "brand_name": "Specialized",
        "foundation": {"core_values": ["innovation", "performance"]},
        "voice_messaging": {"tone": "technical expert"}
    }
    
    message = "I want to compare the aerodynamic performance of your top 3 road bikes"
    
    print(f"üìù Test Message: '{message}'")
    
    start_time = datetime.now()
    prompt_result = await prompt_generator.generate_enhanced_prompt(
        enhanced_context=enhanced_context,
        message=message,
        brand_intelligence=brand_intelligence
    )
    processing_time = (datetime.now() - start_time).total_seconds() * 1000
    
    print(f"\n‚è±Ô∏è  Prompt Generation Time: {processing_time:.1f}ms")
    print(f"üóùÔ∏è  Prompt Key: {prompt_result['prompt_key']}")
    print(f"üéØ Confidence Score: {prompt_result['confidence_score']:.2f}")
    
    # Show the full enhanced prompt
    print(f"\nüìã Complete Enhanced Prompt:")
    print("-" * 40)
    print(prompt_result['enhanced_prompt'])
    print("-" * 40)
    
    # Show prompt variables structure
    print(f"\nüîß Prompt Variables Structure:")
    variables = prompt_result['prompt_variables']
    for key, value in variables.items():
        if isinstance(value, dict):
            print(f"   {key}:")
            for subkey in value.keys():
                print(f"     - {subkey}")
        else:
            print(f"   {key}: {type(value).__name__}")

async def main():
    """Run all enhanced prompt generation tests"""
    
    try:
        # Test standalone prompt generator
        await test_prompt_generator_standalone()
        
        # Test full prompt generation pipeline
        await test_enhanced_prompt_generation()
        
        print("\n\nüéâ All Enhanced Prompt Generation Tests Completed!")
        print("\nüìä Summary:")
        print("‚úÖ Multi-agent psychology analysis working")
        print("‚úÖ Enhanced prompt generation functional")  
        print("‚úÖ Langfuse integration ready")
        print("‚úÖ Conversation Engine integration prepared")
        print("‚úÖ LiveKit context tracking working")
        
    except Exception as e:
        print(f"\n‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
# System Prompt Generation Plan
## From Brand Research to Optimized AI Persona

### Overview
This plan outlines how to systematically generate concise, effective AI persona system prompts from comprehensive brand research while maintaining <1,500 token limits and voice-optimized performance.

---

## Phase 1: Research Analysis & Extraction

### 1.1 Core Variable Extraction
Extract these essential elements from research phases:

**From Foundation Research:**
- Brand mission (1 line)
- Core values (3-5 words)
- Key philosophy/tagline
- 2-3 heritage milestones

**From Voice Messaging Research:**
- Brand voice description (1 line)
- Communication pattern
- Power words and phrases
- Tone preferences

**From Customer Cultural Research:**
- 3 primary segments with %
- Segment characteristics (5-7 words each)
- Detection cues (keywords)

**From Product/Technical Research:**
- 5-7 signature technologies
- Tier structure
- Key metrics/proof points

### 1.2 Content Prioritization
Apply the "Visible vs Internal" rule:
- **Visible**: Rules, patterns, essential guidance
- **Internal**: Lists, matrices, examples, detailed segments

---

## Phase 2: Template Population

### 2.1 Structured Sections (Visible)

**Section 1: Brand Essence** (≤70 tokens)
- Philosophy, mission, values, signature tech, voice
- Single table format
- Include heritage tagline

**Section 2: Tone Controls** (≤40 tokens)
- Single unified slider table
- 5 levels with word counts
- "+1 for more detail" rule

**Section 3: Speaking Rules** (≤70 tokens)
- 7-8 numbered rules max
- Include echo guard
- Benefit → proof (≤10 words) → question pattern
- Reference segments by name only

**Section 4: Consultation Flow** (≤40 tokens)
- 3-step discovery pattern
- Response framework (1 line)

**Section 5: Sales & Fulfillment** (≤60 tokens)
- Core policies (bullets)
- Easy returns mention
- Fulfillment options (brief)

**Section 6: Tool Usage** (≤50 tokens)
- 5-step table format
- 15-word closing phrase
- "(stay within word cap)" reminder

**Section 7: Terminology** (≤30 tokens)
- 1 line on tier vocabulary
- 2-3 translation examples

**Section 8: Policies** (≤20 tokens)
- Single line of key policies

### 2.2 Internal Section (≤600 tokens)
Structure for quick reference:
- LLM parameters
- Customer segments (detailed)
- Detection cues (table)
- Trust builders (bullets)
- Objection matrix (table)
- Metrics library
- Closing phrases

---

## Phase 3: Optimization Rules

### 3.1 Token Reduction Strategies

**Length Control:**
- Single source of truth for word limits (Tone Controls only)
- Remove all duplicate length references
- Use table formats over prose

**Content Compression:**
- Combine related concepts
- Use " · " separators for lists
- Abbreviate where clear (e.g., "Body Geo")

**Strategic Placement:**
- Long lists → Internal section
- Examples → Internal section  
- Detailed explanations → Cut or simplify

### 3.2 Voice Optimization

**Anti-Echo Measures:**
- Explicit "never repeat user's words" rule
- Vary response starters
- Monitor for echo patterns

**Brevity Enforcement:**
- Word count limits in slider
- Monitoring rule for averages
- Short, action-oriented closings

---

## Phase 4: Quality Assurance

### 4.1 Validation Checklist
- [ ] Total tokens ≤1,500
- [ ] No duplicate length guidance
- [ ] Echo guard in place
- [ ] Customer segments referenced but detailed internally
- [ ] One-product rule preserved
- [ ] 15-word closing phrase included
- [ ] Premium tier vocabulary integrated

### 4.2 Testing Protocol
1. Generate prompt from template
2. Count tokens
3. Test with sample conversations
4. Monitor word count averages
5. Check for echo behavior
6. Validate segment adaptation

---

## Phase 5: Continuous Improvement

### 5.1 Feedback Integration
- Collect conversation analytics
- Track conversion metrics
- Monitor average response lengths
- Identify missing objection handlers

### 5.2 Research Updates
- Quarterly research refresh
- New product/tech additions
- Customer segment evolution
- Competitive landscape changes

### 5.3 Version Control
- Semantic versioning (4.1, 4.2, etc.)
- Change log maintenance
- A/B testing capability
- Rollback procedures

---

## Implementation Workflow

### For New Brands:
1. Complete 8-phase research
2. Extract variables using mapping guide
3. Populate template following token limits
4. Apply optimization rules
5. Validate and test
6. Deploy with monitoring

### For Existing Brands:
1. Audit current prompt against research
2. Identify gaps and redundancies
3. Refactor using template structure
4. Apply token reduction strategies
5. Test and compare performance
6. Deploy improved version

---

## Key Success Metrics

**Prompt Quality:**
- Tokens used vs limit (target: 1,300-1,500)
- Research coverage (>80% of key insights)
- Segment adaptation accuracy

**Conversation Performance:**
- Average words per response
- Echo frequency (<5%)
- Conversion rate
- Customer satisfaction

**Maintenance Efficiency:**
- Time to update prompt
- Consistency across brands
- Version deployment speed

---

## Tools & Automation Opportunities

1. **Research Parser**: Extract variables from research markdown
2. **Token Counter**: Real-time token tracking during editing
3. **Prompt Validator**: Check against rules and limits
4. **Version Differ**: Track changes between versions
5. **Performance Monitor**: Track conversation metrics

This plan ensures consistent, high-quality AI personas that leverage comprehensive research while meeting the practical constraints of voice commerce applications.
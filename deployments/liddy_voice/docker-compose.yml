services:
  voice-agent:
    build:
      context: ../..
      dockerfile: deployments/liddy_voice/Dockerfile
    image: voice-agent-test:local
    env_file:
      - ../../.env  # Use the root .env file
    ports:
      - "8081:8081"
    environment:
      # Core settings
      - ENV_TYPE=development  # Change to production when ready
      - STORAGE_PROVIDER=gcp
      
      # LiveKit configuration (required)
      - LIVEKIT_URL=${LIVEKIT_URL}
      - LIVEKIT_API_KEY=${LIVEKIT_API_KEY}
      - LIVEKIT_API_SECRET=${LIVEKIT_API_SECRET}
      - LIVEKIT_PORT=8081
      
      # LLM API Keys (required)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
      
      # Speech services (required)
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY}
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - ELEVEN_API_KEY=${ELEVENLABS_API_KEY}
      
      # Model configuration
      - MODEL_NAME=gpt-4o-mini
      - FALLBACK_MODEL_NAME=gemini-2.0-flash-exp
      
      # Voice settings
      - VOICE_MODEL=eleven_flash_v2_5
      - VOICE_STABILITY=0.6
      - VOICE_SIMILARITY_BOOST=0.8
      - USE_NOISE_CANCELLATION=false
      
      # Storage buckets
      - STORAGE_BUCKET=liddy-conversations
      - PROMPTS_BUCKET=liddy-account-documents-dev  # Use dev for local testing
      
      # Redis (optional for local testing)
      # - REDIS_HOST=host.docker.internal
      # - REDIS_PORT=6379
      
      # Python optimizations
      - PYTHONFAULTHANDLER=1
      - PYTHONUNBUFFERED=1
      
    volumes:
      # Mount GCP credentials
      - ~/.config/gcloud:/home/appuser/.config/gcloud:ro
      # If using service account key:
      # - ./service-account-key.json:/tmp/gcp-key.json:ro
    # environment:
      # - GOOGLE_APPLICATION_CREDENTIALS=/tmp/gcp-key.json
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s